{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/AC 209A/STAT 121A Data Science: Homework 5\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**Instructors: W. Pan, P. Protopapas, K. Rader**<br>\n",
    "**Due Date: ** Wednesday, October 26th, 2016 at 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit your assignment, in Vocareum, upload (using the 'Upload' button on your Vocareum Jupyter Dashboard) your solution to Vocareum as a single notebook with following file name format:\n",
    "\n",
    "`last_first_CourseNumber_HW4.ipynb`\n",
    "\n",
    "where `CourseNumber` is the course in which you're enrolled (CS 109a, Stats 121a, AC 209a). Submit your assignment in Vocareum using the 'Submit' button.\n",
    "\n",
    "**Verify your submission by checking your submission status on Vocareum!**\n",
    "\n",
    "**Avoid editing your file in Vocareum after uploading. If you need to make a change in a solution. Delete your old solution file from Vocareum and upload a new solution. Click submit only ONCE after verifying that you have uploaded the correct file. The assignment will CLOSE after you click the submit button.**\n",
    "\n",
    "Problems on homework assignments are equally weighted. The Challenge Question is required for AC 209A students and optional for all others. Student who complete the Challenge Problem as optional extra credit will receive +0.5% towards your final grade for each correct solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 0: Basic Information\n",
    "\n",
    "Fill in your basic information. \n",
    "\n",
    "### Part (a): Your name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Last, First]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Course Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CS 109a or STATS 121a or AC 209a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Who did you work with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[First and Land names of students with whom you have collaborated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All data sets can be found in the ``datasets`` folder and are in comma separated value (CSV) format**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Image Classification\n",
    "\n",
    "In this problem, your task is to classify images of handwritten digits. \n",
    "\n",
    "The data set is provided in the file `dataset_1.txt` and contains 8x8 gray-scale images of hand-written digits, flattened to a 64-length vector. The last column contains the digit. For simplicity, we have only included digits 0, 1 and 3. \n",
    "\n",
    "We want you to build a model that can be given the image of a hand-written digit and correctly classify this digit as 0, 1 or 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1(a).  Reduce the data\n",
    "\n",
    "Images data are typically high dimensional (the image vector has one feature for every pixel). Thus, to make working with image data more tractible, one might first apply a dimension reduction technique to the data.\n",
    "\n",
    "- Explain why PCA is a better choice for dimension reduction in this problem than step-wise variable selection.\n",
    "\n",
    "\n",
    "- Choose the smallest possible number of dimensions for PCA that still permits us to perform classification. \n",
    "\n",
    "  (**Hint:** how do we visually verify that subgroups in a dataset are easily classifiable?)\n",
    "\n",
    "\n",
    "- Visualize and interpret the principal components. Interpret, also, the corresponding PCA varaiable values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1(b). Build a classifier\n",
    "\n",
    "So far, we have only learned models that distinguishes between two classes. Develop and implement a **simple and naive** method of distinguishing between the three digits in our reduced dataset using binary classifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1(c). Build a better one\n",
    "Asses the quality of your classifier.\n",
    "\n",
    "\n",
    "- What is the fit (in terms of accuracy or R^2) of your model on the reduced dataset? Visually assess the quality of your classifier by plotting decision surfaces along with the data. Why is visualization of the decision surfaces useful? What does this visualization tell you that a numberical score (like accuracy or R^2) cannot?\n",
    "\n",
    "\n",
    "- What are the draw backs of your approach to multi-class classification? What aspects of your method is contributing to these draw backs, i.e. why does it fail when it does? \n",
    "\n",
    "  (**Hint:** make use your analysis in the above; think about what happens when we have to classify 10 classes, 100 classes)\n",
    " \n",
    " \n",
    "- Describe a possibly better alternative for fitting a multi-class model. Specifically address why you expect the alternative model to outperform your model.\n",
    "\n",
    "  (**Hint:** How does ``sklearn``'s Logistic regression module handle multiclass classification?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you will explore how to predict the underlying emotional tone of textual data - this task is called sentiment analysis. \n",
    "\n",
    "You will be using the dataset in the file `dataset_2.txt`. In this dataset, there are 1382 posts containing textual opinions about Ford automobiles, along with labels indicating whether the opinion expressed is positive or negative. \n",
    "\n",
    "Given a new post about an automobile, your goal is to predict if the sentiment expressed in the new post is positive or negative. For this task you should implement a *regularized* logistic regression model.\n",
    "\n",
    "Produce a report summarizing your solution to this problem:\n",
    "\n",
    "- Your report should address all decisions you made in the \"Data Science Process\" (from Lectures #0, #1, #2):\n",
    "\n",
    "   a. Data collection & cleaning\n",
    "   \n",
    "   b. Data exploration\n",
    "   \n",
    "   c. Modeling\n",
    "   \n",
    "   d. Analysis  \n",
    "   \n",
    "   e. Visualization and presentation  \n",
    "\n",
    "\n",
    "- Your report should be informative and accessible to a **general audience with no assumed formal training in mathematics, statistics or computer science**.\n",
    "\n",
    "\n",
    "- The exposition in your report, not including code, visualization and output, should be at least three paragraphs in length (you are free to write more, but you're not required to).\n",
    "\n",
    "Structure your presentation and exposition like a professional product that can be submitted to a client and or your supervisor at work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Problem: Automated Medical Diagnosis\n",
    "\n",
    "In this problem, you are going to build a model to diagnose heart disease. \n",
    "\n",
    "The training set is provided in the file ``dataset_3_train.txt`` and there are two test sets: ``dataset_3_test_1.txt`` and ``dataset_3_test_2.txt``. Each patient in the datasets is described by 5 biomarkers extracted from cardiac SPECT images; the last column in each dataset contains the disease diagnosis (1 indicates that the patient is normal, and 0 indicates that the patient suffers from heart disease).\n",
    "\n",
    "- Fit a logistic regression model to the training set, and report its accuracy on both the test sets. \n",
    "\n",
    "\n",
    "- Is your accuracy rate meaningful or reliable? How comfortable would you be in using your predictions to diagnose real living patients? Justify your answers. \n",
    "\n",
    "  (**Hint:** How does the performance of your model compare with a classifier that lumps all patients into the same class?)\n",
    "\n",
    "\n",
    "- Let's call the logistic regression model you learned, ${C}_1$. Your colleague suggests that you can get higher accuracies for this task by using a threshold of 0.05 on the Logistic regression model to predict labels instead of the usual threshold of 0.5, i.e. use a classifier that predicts 1 when $\\widehat{P}(Y = 1\\,|\\, X) \\geq 0.05$ and 0 otherwise. Let's call this classifier ${C}_2$. Does ${C}_2$ perform better the two test sets - that is, which one would you rather use for automated diagnostics? Support your conclusion with careful analysis. \n",
    "\n",
    "\n",
    "- Generalize your analysis of these two classifiers. Under what general conditions does $C_2$ perform better than ${C}_1$? Support your conclusion with a mathematical proof or simulation\n",
    "\n",
    "\n",
    "**Hint:** You were told in class that a classifier that predicts 1 when $\\widehat{P}(Y = 1 \\,|\\, X) \\geq 0.5$, and 0 otherwise, is the Bayes classifier. This classifier minimizes the classification error rate. What can you say about a classifier that uses a threshold other than $0.5$? Is it the Bayes classifier for a different loss function?\n",
    "\n",
    "\n",
    "**Hint:** For the first three parts, you might find it useful to analyze the conditional accuracy on each class."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
